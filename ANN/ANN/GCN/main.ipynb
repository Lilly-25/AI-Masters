{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import tools\n",
    "import tests\n",
    "\n",
    "from model import GNN\n",
    "from data import Sudoku\n",
    "\n",
    "# plt.rc('figure', max_open_warning = 0)\n",
    "\n",
    "\n",
    "import argparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = argparse.ArgumentParser(description=\"PixelCNN\")\n",
    "# parser.add_argument(\n",
    "#     \"--n_epochs\", default=30, type=int, metavar=\"N\", help=\"number of epochs to run training loop with default = 11\"\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\n",
    "#     \"-b\", \"--batch_size\", default=16, type=int, metavar=\"N\", help=\"batch size training with default = 32\"\n",
    "# )\n",
    "\n",
    "# parser.add_argument(\"--cuda\", dest=\"cuda\", action=\"store_false\", help=\"use cuda\")\n",
    "\n",
    "# parser.add_argument(\"--skip_training\", dest=\"skip_training\", action=\"store_true\", help=\"skip training\")\n",
    "\n",
    "# parser.add_argument(\"-lr\", \"--learning_rate\", default=0.001, type=float, metavar=\"LR\", help=\"learning rate\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sudoku_edges():\n",
    "\n",
    "    flatten_puzzle = np.reshape(np.array(range(81)), (9, 9))\n",
    "    dic = {}\n",
    "    for vert_index, outer_value in enumerate(flatten_puzzle):\n",
    "        if vert_index in (0, 3, 6):\n",
    "            up = 0\n",
    "            down = 2\n",
    "        if vert_index in (1, 4, 7):\n",
    "            up = -1\n",
    "            down = 1\n",
    "        if vert_index in (2, 5, 8):\n",
    "            up = -2\n",
    "            down = 0\n",
    "\n",
    "        for horz_index, inner_value in enumerate(outer_value):\n",
    "            if horz_index in (0, 3, 6):\n",
    "                right = 2\n",
    "                left = 0\n",
    "            if horz_index in (1, 4, 7):\n",
    "                right = 1\n",
    "                left = -1\n",
    "            if horz_index in (2, 5, 8):\n",
    "                right = 0\n",
    "                left = -2\n",
    "\n",
    "            for i in range(up, down + 1, 1):\n",
    "                for j in range(left, right + 1, 1):\n",
    "                    if inner_value not in dic:\n",
    "                        dic[inner_value] = []\n",
    "                    if flatten_puzzle[vert_index + i][horz_index + j] != inner_value:\n",
    "                        dic[inner_value].append(flatten_puzzle[vert_index + i][horz_index + j])\n",
    "\n",
    "            for i in outer_value:\n",
    "                if inner_value != i:\n",
    "                    dic[inner_value].append(i)\n",
    "\n",
    "            for l in flatten_puzzle:\n",
    "                if inner_value != l[horz_index]:\n",
    "                    dic[inner_value].append(l[horz_index])\n",
    "            dic[inner_value] = set(dic[inner_value])\n",
    "\n",
    "    src_ids = [[x] * 20 for x in dic.keys()]\n",
    "    src_ids = torch.Tensor([x for y in src_ids for x in y]).type(torch.LongTensor)\n",
    "    dst_ids = [y for y in dic.values()]\n",
    "\n",
    "    dst_ids = torch.Tensor([x for y in dst_ids for x in y]).type(torch.LongTensor)\n",
    "\n",
    "    return src_ids, dst_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(list_of_samples):\n",
    "    \"\"\"Merges a list of samples to form a mini-batch.\n",
    "\n",
    "    Args:\n",
    "      list_of_samples is a list of tuples (inputs, targets),\n",
    "          inputs of shape (n_nodes, 9): Inputs to each node in the graph. Inputs are one-hot coded digits\n",
    "              in the sudoku puzzle. A missing digit is encoded with all zeros. n_nodes=81 for the sudoku graph.\n",
    "          targets of shape (n_nodes): A LongTensor of targets (correct digits in the sudoku puzzle).\n",
    "\n",
    "    Returns:\n",
    "      inputs of shape (batch_size*n_nodes, 9): Inputs to each node in the graph. Inputs are one-hot coded digits\n",
    "          in the sudoku puzzle. A missing digit is encoded with all zeros. n_nodes=81 for the sudoku graph.\n",
    "      targets of shape (batch_size*n_nodes): A LongTensor of targets (correct digits in the sudoku puzzle).\n",
    "      src_ids of shape (batch_size*1620): LongTensor of source node ids for each edge in the large graph.\n",
    "          The source ids should be between 0 and batch_size * 81.\n",
    "      dst_ids of shape (batch_size*1620): LongTensor of destination node ids for each edge in the large graph.\n",
    "          The destination ids should be between 0 and batch_size * 81.\n",
    "    \"\"\"\n",
    "    inputs = [tup[0] for tup in list_of_samples]\n",
    "    inputs = torch.cat(inputs, 0)\n",
    "    targets = [tup[1] for tup in list_of_samples]\n",
    "    targets = torch.cat(targets, 0)\n",
    "    batch = len(list_of_samples)\n",
    "    src, dst = sudoku_edges()\n",
    "    src_ids = torch.cat([src + 81 * i for i in range(batch)], 0)\n",
    "    dst_ids = torch.cat([dst + 81 * i for i in range(batch)], 0)\n",
    "    return inputs, targets, src_ids, dst_ids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction_of_solved_puzzles(gnn, testloader, device):\n",
    "    with torch.no_grad():\n",
    "        n_test = 0\n",
    "        n_test_solved = 0\n",
    "        for i, (inputs, targets, src_ids, dst_ids) in enumerate(testloader):\n",
    "            batch_size = inputs.size(0) // 81\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            src_ids, dst_ids = src_ids.to(device), dst_ids.to(device)\n",
    "\n",
    "            outputs = gnn(inputs, src_ids, dst_ids)  # [n_iters, batch*n_nodes, 9]\n",
    "            solution = outputs.view(gnn.n_iters, batch_size, 9, 9, 9)\n",
    "\n",
    "            final_solution = solution[-1].argmax(dim=3).to(device)\n",
    "            solved = (final_solution.view(-1, 81) == targets.view(batch_size, 81)).all(dim=1)\n",
    "            n_test += solved.size(0)\n",
    "            n_test_solved += solved.sum().item()\n",
    "            return n_test_solved / n_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    args = parser.parse_args()\n",
    "    if args.cuda:\n",
    "        device = torch.device(\"cuda:0\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    data_dir = tools.select_data_dir()\n",
    "\n",
    "    trainset = Sudoku(data_dir, train=True)\n",
    "    testset = Sudoku(data_dir, train=False)\n",
    "\n",
    "    trainloader = DataLoader(trainset, batch_size=args.batch_size, collate_fn=collate)\n",
    "    testloader = DataLoader(testset, batch_size=args.batch_size, collate_fn=collate)\n",
    "\n",
    "    # Create network\n",
    "    gnn = GNN(device)\n",
    "    if not args.skip_training:\n",
    "        optimizer = torch.optim.Adam(gnn.parameters(), lr=args.learning_rate)\n",
    "        loss_method = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "\n",
    "        for epoch in range(args.n_epochs):\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                inputs, targets, src_ids, dst_ids = data\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                src_ids, dst_ids = src_ids.to(device), dst_ids.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                gnn.zero_grad()\n",
    "                output = gnn.forward(inputs, src_ids, dst_ids)\n",
    "                output = output.to(device)\n",
    "                output = output.view(-1, output.shape[2])\n",
    "                targets = targets.repeat(7, 1)\n",
    "                targets = targets.view(-1)\n",
    "                loss = loss_method(output, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            fraction = fraction_of_solved_puzzles(gnn, testloader, device)\n",
    "\n",
    "            print(\"Train Epoch {}: Loss: {:.6f} Fraction: {}\".format(epoch + 1, loss.item(), fraction))\n",
    "\n",
    "        tools.save_model(gnn, \"7_gnn.pth\")\n",
    "    else:\n",
    "        gnn = GNN(device)\n",
    "        tools.load_model(gnn, \"7_gnn.pth\", device)\n",
    "\n",
    "    # Evaluate the trained model\n",
    "    # Get graph iterations for some test puzzles\n",
    "    with torch.no_grad():\n",
    "        inputs, targets, src_ids, dst_ids = iter(testloader).next()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        src_ids, dst_ids = src_ids.to(device), dst_ids.to(device)\n",
    "\n",
    "        batch_size = inputs.size(0) // 81\n",
    "        outputs = gnn(inputs, src_ids, dst_ids).to(device)  # [n_iters, n_nodes, 9]\n",
    "\n",
    "        solution = outputs.view(gnn.n_iters, batch_size, 9, 9, 9).to(device)\n",
    "        final_solution = solution[-1].argmax(dim=3).to(device)\n",
    "        print(\"Solved puzzles in the current mini-batch:\")\n",
    "        print((final_solution.view(-1, 81) == targets.view(batch_size, 81)).all(dim=1))\n",
    "\n",
    "    # Visualize graph iteration for one of the puzzles\n",
    "    ix = 0\n",
    "    for i in range(gnn.n_iters):\n",
    "        tools.draw_sudoku(solution[i, 0], logits=True)\n",
    "\n",
    "    fraction_solved = fraction_of_solved_puzzles(gnn, testloader,device)\n",
    "    print(f\"Accuracy {fraction_solved}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--n_epochs N] [-b N] [--cuda]\n",
      "                             [--skip_training] [-lr LR]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=/home/lilly/.local/share/jupyter/runtime/kernel-v2-44866118nA0T9L2A6v.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
