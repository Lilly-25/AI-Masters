{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-07-27T06:27:37.928669Z",
     "iopub.status.busy": "2022-07-27T06:27:37.928037Z",
     "iopub.status.idle": "2022-07-27T06:27:39.993359Z",
     "shell.execute_reply": "2022-07-27T06:27:39.992263Z",
     "shell.execute_reply.started": "2022-07-27T06:27:37.928579Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import glob, os\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import random as random\n",
    "\n",
    "# set the device which will be used to train the model\n",
    "device = torch.device('cuda:0' if torch.cuda.device_count() >= 1 else 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise1: Data Set Exploration and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = './train'\n",
    "test_path = './test'\n",
    "train_file_names = open(\"train.txt\", \"r\").read().splitlines()\n",
    "eval_file_names = open(\"eval.txt\", \"r\").read().splitlines()\n",
    "test_file_names = os.listdir(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_labels = {\"boxing\" : 0, \"drums\" : 1, \"guitar\" : 2, \"rowing\" : 3, \"violin\" : 4}\n",
    "num_categories = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_names.sort(key=lambda x: int(x[:x.index('.')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253.674301</td>\n",
       "      <td>102.96611</td>\n",
       "      <td>0.9078</td>\n",
       "      <td>269.803192</td>\n",
       "      <td>191.368973</td>\n",
       "      <td>0.785458</td>\n",
       "      <td>201.43306</td>\n",
       "      <td>201.431473</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>181.371231</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>201.00000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.159373</td>\n",
       "      <td>0.426741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.159373</td>\n",
       "      <td>0.426741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.159373</td>\n",
       "      <td>0.426741</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>201.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.199359</td>\n",
       "      <td>0.532487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.199359</td>\n",
       "      <td>0.532487</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.199359</td>\n",
       "      <td>0.532487</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>202.00000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272133</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272133</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.272133</td>\n",
       "      <td>0.604508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>203.00000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.865690</td>\n",
       "      <td>-4.388336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.865690</td>\n",
       "      <td>-4.388336</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.865690</td>\n",
       "      <td>-4.388336</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>269.000000</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>215.00000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.497719</td>\n",
       "      <td>3.344067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.497719</td>\n",
       "      <td>3.344067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.497719</td>\n",
       "      <td>3.344067</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>273.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>219.00000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.458832</td>\n",
       "      <td>3.297691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.458832</td>\n",
       "      <td>3.297691</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.458832</td>\n",
       "      <td>3.297691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>277.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>223.00000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.466545</td>\n",
       "      <td>3.380524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.466545</td>\n",
       "      <td>3.380524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.466545</td>\n",
       "      <td>3.380524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>230.00000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.506676</td>\n",
       "      <td>3.337200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.506676</td>\n",
       "      <td>3.337200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.506676</td>\n",
       "      <td>3.337200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>287.000000</td>\n",
       "      <td>83.00000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>235.00000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.511330</td>\n",
       "      <td>3.321026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.511330</td>\n",
       "      <td>3.321026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.511330</td>\n",
       "      <td>3.321026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1       2           3           4         5  \\\n",
       "0    253.674301  102.96611  0.9078  269.803192  191.368973  0.785458   \n",
       "1    253.000000  102.00000  1.0000  270.000000  191.000000  1.000000   \n",
       "2    253.000000  102.00000  1.0000  272.000000  189.000000  1.000000   \n",
       "3    253.000000  102.00000  1.0000  272.000000  189.000000  1.000000   \n",
       "4    254.000000  101.00000  1.0000  273.000000  189.000000  1.000000   \n",
       "..          ...        ...     ...         ...         ...       ...   \n",
       "217  269.000000   86.00000  1.0000  291.000000  182.000000  1.000000   \n",
       "218  273.000000   85.00000  1.0000  295.000000  182.000000  1.000000   \n",
       "219  277.000000   85.00000  1.0000  300.000000  182.000000  1.000000   \n",
       "220  282.000000   84.00000  1.0000  305.000000  182.000000  1.000000   \n",
       "221  287.000000   83.00000  1.0000  310.000000  182.000000  1.000000   \n",
       "\n",
       "             6           7       8           9  ...   65         66        67  \\\n",
       "0    201.43306  201.431473  0.8228  181.371231  ...  0.0   0.000000  0.000000   \n",
       "1    201.00000  202.000000  1.0000  181.000000  ...  0.0  -0.159373  0.426741   \n",
       "2    201.00000  203.000000  1.0000  181.000000  ...  0.0  -0.199359  0.532487   \n",
       "3    202.00000  204.000000  1.0000  182.000000  ...  0.0   0.272133  0.604508   \n",
       "4    203.00000  204.000000  1.0000  184.000000  ...  0.0  -0.865690 -4.388336   \n",
       "..         ...         ...     ...         ...  ...  ...        ...       ...   \n",
       "217  215.00000  193.000000  1.0000  196.000000  ...  0.0 -25.497719  3.344067   \n",
       "218  219.00000  193.000000  1.0000  199.000000  ...  0.0 -25.458832  3.297691   \n",
       "219  223.00000  191.000000  1.0000  202.000000  ...  0.0 -25.466545  3.380524   \n",
       "220  230.00000  190.000000  1.0000  204.000000  ...  0.0 -25.506676  3.337200   \n",
       "221  235.00000  189.000000  1.0000  208.000000  ...  0.0 -25.511330  3.321026   \n",
       "\n",
       "      68         69        70   71         72        73   74  \n",
       "0    0.0   0.000000  0.000000  0.0   0.000000  0.000000  0.0  \n",
       "1    0.0  -0.159373  0.426741  0.0  -0.159373  0.426741  0.0  \n",
       "2    0.0  -0.199359  0.532487  0.0  -0.199359  0.532487  0.0  \n",
       "3    0.0   0.272133  0.604508  0.0   0.272133  0.604508  0.0  \n",
       "4    0.0  -0.865690 -4.388336  0.0  -0.865690 -4.388336  0.0  \n",
       "..   ...        ...       ...  ...        ...       ...  ...  \n",
       "217  0.0 -25.497719  3.344067  0.0 -25.497719  3.344067  0.0  \n",
       "218  0.0 -25.458832  3.297691  0.0 -25.458832  3.297691  0.0  \n",
       "219  0.0 -25.466545  3.380524  0.0 -25.466545  3.380524  0.0  \n",
       "220  0.0 -25.506676  3.337200  0.0 -25.506676  3.337200  0.0  \n",
       "221  0.0 -25.511330  3.321026  0.0 -25.511330  3.321026  0.0  \n",
       "\n",
       "[222 rows x 75 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_frame_list = []\n",
    "eval_data_frame_list = []\n",
    "eval_index_list = []\n",
    "for index in range(len(train_file_names)):\n",
    "    with open(os.path.join(train_path, train_file_names[index]), \"r\") as f:\n",
    "        content = f.readlines()\n",
    "        train_data_frame_list.append(pd.DataFrame([[float(p) for p in st.split(',')] for st in content[:len(content) // 2]]))\n",
    "        train_data_frame_list[-1].columns = [str(i) for i in range(len(train_data_frame_list[-1].columns))]\n",
    "\n",
    "for index in range(len(eval_file_names)):\n",
    "    with open(os.path.join(train_path, eval_file_names[index]), \"r\") as f:\n",
    "        content = f.readlines()\n",
    "        eval_data_frame_list.append(pd.DataFrame([[float(p) for p in st.split(',')] for st in content[:len(content) // 2]]))\n",
    "        eval_data_frame_list[-1].columns = [str(i) for i in range(len(eval_data_frame_list[-1].columns))]\n",
    "        eval_index_list.append(index)\n",
    "\n",
    "train_data_frame_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1407f8f62e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnV0lEQVR4nO3df3DU9Z3H8dcmkASE3TRAsklJbBQPzIUfBy2w1x69k0hCkcOKM+L5g3oeTtPgqHgcxbNwOD3j2U5b7SjctFOxo8idHZEDJT0uSDzryo9gTgKaEybXcJJNkEx2A5oA2c/9we3WhQBZspv9bPb5mNkZ9vv9JHl/+Ab35ef7+Xy+DmOMEQAAgEXSEl0AAADAhQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrDEt0AVcjGAzq+PHjGj16tBwOR6LLAQAA/WCMUVdXlwoKCpSWdvkxkqQMKMePH1dhYWGiywAAAFfh2LFjGj9+/GXbJGVAGT16tKTzHXQ6nQmuBgAA9EcgEFBhYWH4c/xykjKghG7rOJ1OAgoAAEmmP9MzmCQLAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFgnKTdqA4Bk0hs02tvcofaubuWOztLM4hylp/EcMeByCCgAEEc1ja1at+2wWv3d4WP5riytXViiitL8BFYG2I1bPAAQJzWNrap86UBEOJEkn79blS8dUE1ja4Iqi6/eoJH36EltbfhE3qMn1Rs0iS4JSYgRFACIg96g0bpth9XXR7OR5JC0btth3VziHlK3exgxQqwwggIAcbC3ueOikZMvMpJa/d3a29wxeEXFWSqNGDFKFH+MoABAHLR3XTqcXE0726XSiBGjRIODERQAiIPc0VkxbWe7VBkxSqVRokQjoABAHMwszlG+K0uXGitw6Pz/dc8szhnMsuImFUaMrjRKJJ0fJeJ2T2wQUAAgDtLTHFq7sESSLgopofdrF5Yk/e2OkFQYMUqVUSJbEFAAIE4qSvO1/u7pcrsiP5Tdriytv3v6kJqvkAojRqkwSmQTJskCQBxVlObr5hL3kN9JNjRiVPnSATmkiNsgQ2XEKBVGiWwyoBGUp556Sg6HQw8//HD4WHd3t6qqqjRmzBiNGjVKixcvVltbW8TXtbS0aMGCBRo5cqRyc3O1cuVKnTt3biClAIC10tMc8lw/RoumfVme68ck9Yf05Qz1EaNUGCWyyVWPoOzbt0///M//rClTpkQcf+SRR/TGG2/o1Vdflcvl0vLly3Xbbbfpd7/7nSSpt7dXCxYskNvt1rvvvqvW1lbde++9Gj58uJ588smB9QZA3PA8GfTHUB4xSoVRIps4jDFRTzc+deqUpk+frueff14//OEPNW3aNP3sZz+T3+/XuHHjtGnTJt1+++2SpI8++kg33nijvF6vZs+erR07duiWW27R8ePHlZeXJ0nasGGDVq1apRMnTigjI+OKPz8QCMjlcsnv98vpdEZbPoAose8D8Af8e7h60Xx+X9UtnqqqKi1YsEBlZWURx+vr63X27NmI45MmTVJRUZG8Xq8kyev1avLkyeFwIknl5eUKBAI6dOjQ1ZQDII7Y9wGIVFGar3dW3aRXls3WM0um6ZVls/XOqpsIJzEW9S2ezZs368CBA9q3b99F53w+nzIyMpSdnR1xPC8vTz6fL9zmi+EkdD50ri89PT3q6ekJvw8EAtGWDeAqpNLuoEA0QvOKED9RjaAcO3ZMDz30kF5++WVlZQ3eLOXq6mq5XK7wq7CwcNB+NpDK2PcBQKJEFVDq6+vV3t6u6dOna9iwYRo2bJjq6ur07LPPatiwYcrLy9OZM2fU2dkZ8XVtbW1yu92SJLfbfdGqntD7UJsLrV69Wn6/P/w6duxYNGUDuErs+wCkBhsffhjVLZ65c+fq4MGDEcfuu+8+TZo0SatWrVJhYaGGDx+u2tpaLV68WJLU1NSklpYWeTweSZLH49E//uM/qr29Xbm5uZKknTt3yul0qqSkpM+fm5mZqczMzKg7B2Bg2PcBGPpsnfQbVUAZPXq0SktLI45dc801GjNmTPj4/fffrxUrVignJ0dOp1MPPvigPB6PZs+eLUmaN2+eSkpKdM899+jpp5+Wz+fT448/rqqqKkIIYJnQvg8+f3ef81AcOr/HBfs+AMkpNAn+wn/foUnwidy/JuZb3f/0pz/VLbfcosWLF2vOnDlyu9167bXXwufT09O1fft2paeny+Px6O6779a9996rJ554ItalABigVHueDJBKbH/44VXtg5Jo7IMCDC5bh4ABXD3v0ZO68xfvXbHdK8tmx2zFUjSf3zyLB8AVDeXdQYFUZfskeAIKgH5h3wdgaLF9EnzM56AAAAD72f7wQwIKAAApyPZJ8AQUAABSVEVpvtbfPV1uV+RtHLcrK6FLjCXmoAAAkNJsnQRPQAEAIMXZOAmeWzwAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ1hiS4AwNDXGzTa29yh9q5u5Y7O0sziHKWnORJdFgCLEVAAxFVNY6vWbTusVn93+Fi+K0trF5aoojQ/gZUBsBm3eADETU1jqypfOhARTiTJ5+9W5UsHVNPYmqDKANiOgAIgLnqDRuu2HZbp41zo2Lpth9Ub7KsFgFRHQAEQF3ubOy4aOfkiI6nV3629zR2DVxSApEFAARAX7V2XDidX0w5AaokqoKxfv15TpkyR0+mU0+mUx+PRjh07wue7u7tVVVWlMWPGaNSoUVq8eLHa2toivkdLS4sWLFigkSNHKjc3VytXrtS5c+di0xsA1sgdnRXTdgBSS1QBZfz48XrqqadUX1+v/fv366abbtKiRYt06NAhSdIjjzyibdu26dVXX1VdXZ2OHz+u2267Lfz1vb29WrBggc6cOaN3331XL774ojZu3Kg1a9bEtlcAEm5mcY7yXVm61GJih86v5plZnDOYZQFIEg5jzIBmqOXk5OhHP/qRbr/9do0bN06bNm3S7bffLkn66KOPdOONN8rr9Wr27NnasWOHbrnlFh0/flx5eXmSpA0bNmjVqlU6ceKEMjIy+vUzA4GAXC6X/H6/nE7nQMoHEEehVTySIibLhkLL+runs9QYSCHRfH5f9RyU3t5ebd68WadPn5bH41F9fb3Onj2rsrKycJtJkyapqKhIXq9XkuT1ejV58uRwOJGk8vJyBQKB8ChMX3p6ehQIBCJeAOxXUZqv9XdPl9sVeRvH7coinAC4rKg3ajt48KA8Ho+6u7s1atQobdmyRSUlJWpoaFBGRoays7Mj2ufl5cnn80mSfD5fRDgJnQ+du5Tq6mqtW7cu2lIBWKCiNF83l7jZSRZAVKIOKBMnTlRDQ4P8fr9+85vfaOnSpaqrq4tHbWGrV6/WihUrwu8DgYAKCwvj+jMBxE56mkOe68ckugwASSTqgJKRkaEJEyZIkmbMmKF9+/bpmWee0R133KEzZ86os7MzYhSlra1NbrdbkuR2u7V3796I7xda5RNq05fMzExlZmZGWyoAAEhSA94HJRgMqqenRzNmzNDw4cNVW1sbPtfU1KSWlhZ5PB5Jksfj0cGDB9Xe3h5us3PnTjmdTpWUlAy0FAAAMEC9QSPv0ZPa2vCJvEdPJmy356hGUFavXq358+erqKhIXV1d2rRpk3bv3q3f/va3crlcuv/++7VixQrl5OTI6XTqwQcflMfj0ezZsyVJ8+bNU0lJie655x49/fTT8vl8evzxx1VVVcUICQAACWbTwz2jCijt7e2699571draKpfLpSlTpui3v/2tbr75ZknST3/6U6WlpWnx4sXq6elReXm5nn/++fDXp6ena/v27aqsrJTH49E111yjpUuX6oknnohtrwAAQFRC2wJcOF4SerjnYK+8G/A+KInAPigAAMROb9DoG/+065LPz3Lo/PYA76y6aUAr8AZlHxQAADA02PhwTwIKAAApzsaHexJQAABIcTY+3JOAAgBAirPx4Z4EFAAAUlx6mkNrF57fj+zCkBJ6v3ZhyaA+ooKAAgAArHu4Z9Rb3QMAgKHJpod7ElAAAECYLQ/35BYPAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYZlugCAGAgeoNGe5s71N7VrdzRWZpZnKP0NEeiywIwQAQUAEmrprFV67YdVqu/O3ws35WltQtLVFGan8DKAAxUVLd4qqur9bWvfU2jR49Wbm6ubr31VjU1NUW06e7uVlVVlcaMGaNRo0Zp8eLFamtri2jT0tKiBQsWaOTIkcrNzdXKlSt17ty5gfcGQMqoaWxV5UsHIsKJJPn83ap86YBqGlsTVBmAWIgqoNTV1amqqkrvvfeedu7cqbNnz2revHk6ffp0uM0jjzyibdu26dVXX1VdXZ2OHz+u2267LXy+t7dXCxYs0JkzZ/Tuu+/qxRdf1MaNG7VmzZrY9QrAkNYbNFq37bBMH+dCx9ZtO6zeYF8tACQDhzHmqv8FnzhxQrm5uaqrq9OcOXPk9/s1btw4bdq0Sbfffrsk6aOPPtKNN94or9er2bNna8eOHbrlllt0/Phx5eXlSZI2bNigVatW6cSJE8rIyLjizw0EAnK5XPL7/XI6nVdbPoAk5T16Unf+4r0rtntl2Wx5rh8zCBUB6I9oPr8HtIrH7/dLknJyciRJ9fX1Onv2rMrKysJtJk2apKKiInm9XkmS1+vV5MmTw+FEksrLyxUIBHTo0KGBlAMgRbR3dV+5URTtANjnqifJBoNBPfzww/r617+u0tJSSZLP51NGRoays7Mj2ubl5cnn84XbfDGchM6HzvWlp6dHPT094feBQOBqywYwBOSOzoppOwD2ueoRlKqqKjU2Nmrz5s2xrKdP1dXVcrlc4VdhYWHcfyYAe80szlG+K0uXWkzs0PnVPDOLcwazLAAxdFUBZfny5dq+fbveeustjR8/Pnzc7XbrzJkz6uzsjGjf1tYmt9sdbnPhqp7Q+1CbC61evVp+vz/8Onbs2NWUDWCISE9zaO3CEkm6KKSE3q9dWMJ+KEASiyqgGGO0fPlybdmyRbt27VJxcXHE+RkzZmj48OGqra0NH2tqalJLS4s8Ho8kyePx6ODBg2pvbw+32blzp5xOp0pKSvr8uZmZmXI6nREvAKmtojRf6++eLrcr8jaO25Wl9XdPZx+UKPUGjbxHT2prwyfyHj3JCigkXFSreL73ve9p06ZN2rp1qyZOnBg+7nK5NGLECElSZWWl3nzzTW3cuFFOp1MPPvigJOndd9+VdH6Z8bRp01RQUKCnn35aPp9P99xzj/7mb/5GTz75ZL/qYBUPgBB2kh04NrzDYInm8zuqgOJw9P2P/oUXXtB3vvMdSec3anv00Uf1yiuvqKenR+Xl5Xr++ecjbt/8/ve/V2VlpXbv3q1rrrlGS5cu1VNPPaVhw/o3Z5eAAgCxEdrw7sIPgtB/7RmNQizFLaDYgoACAAPXGzT6xj/tumg33hCHzt8ye2fVTYxKISYGbR8UAEDy2tvccclwIp3flbfV3629zR2DVxTw/wgoAJCi2PAONuNpxgCQotjwLr6YwD0wBBQASFGhDe98/u4+H7wYmoPChnfRY2XUwHGLBwBSFBvexUdoZdSF83t8/m5VvnRANY2tCaosuRBQACCFseFdbPUGjdZtO9zniFTo2Lpth9kIrx+4xQMAKa6iNF83l7iZLxED0ayM8lw/ZvAKS0IEFACA0tMcfGDGACujYodbPAAAxAgro2KHgAIAQIyEVkZd6uaYQ+dX87Ay6soIKAAAxAgro2KHgAIAQAyxMio2mCQLAECMsTJq4AgoAADEASujBoZbPAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYJ1hiS4AAGzWGzTa29yh9q5u5Y7O0sziHKWnORJdFjDkEVAA4BJqGlu1btthtfq7w8fyXVlau7BEFaX5CawMGPq4xQMAfahpbFXlSwciwokk+fzdqnzpgGoaWxNUGZAaCCgAcIHeoNG6bYdl+jgXOrZu22H1BvtqASAWCCgAcIG9zR0XjZx8kZHU6u/W3uaOwSvqAr1BI+/Rk9ra8Im8R08SljDkMAcFAC7Q3nXpcHI17WKNuTFIBYygAMAFckdnxbRdLDE3Bqki6oDy9ttva+HChSooKJDD4dDrr78ecd4YozVr1ig/P18jRoxQWVmZPv7444g2HR0duuuuu+R0OpWdna37779fp06dGlBHACBWZhbnKN+VpUstJnbo/IjFzOKcwSyLuTFIKVEHlNOnT2vq1Kl67rnn+jz/9NNP69lnn9WGDRu0Z88eXXPNNSovL1d39x/S/l133aVDhw5p586d2r59u95++2098MADV98LAIih9DSH1i4skaSLQkro/dqFJYO+H0oyzI0BYiXqOSjz58/X/Pnz+zxnjNHPfvYzPf7441q0aJEk6de//rXy8vL0+uuva8mSJfrwww9VU1Ojffv26atf/aok6ec//7m+9a1v6cc//rEKCgoG0B0AiI2K0nytv3v6RXM93Amc62H73BgglmI6Sba5uVk+n09lZWXhYy6XS7NmzZLX69WSJUvk9XqVnZ0dDieSVFZWprS0NO3Zs0ff/va3L/q+PT096unpCb8PBAKxLBsA+lRRmq+bS9zW7CRr89wYINZiGlB8Pp8kKS8vL+J4Xl5e+JzP51Nubm5kEcOGKScnJ9zmQtXV1Vq3bl0sSwWAfklPc8hz/ZhElyHpD3NjfP7uPuehOHR+hGew58YA8ZAUq3hWr14tv98ffh07dizRJQHAoLN1bsxAsacL+hLTERS32y1JamtrU37+H+7PtrW1adq0aeE27e3tEV937tw5dXR0hL/+QpmZmcrMzIxlqQCQlGycGzMQ7OmCS4lpQCkuLpbb7VZtbW04kAQCAe3Zs0eVlZWSJI/Ho87OTtXX12vGjBmSpF27dikYDGrWrFmxLAcAhiTb5sZcrdCeLheOl4T2dFl/93RCSgqLOqCcOnVKR44cCb9vbm5WQ0ODcnJyVFRUpIcfflg//OEPdcMNN6i4uFg/+MEPVFBQoFtvvVWSdOONN6qiokLLli3Thg0bdPbsWS1fvlxLlixhBQ+AIak3aGIeJmyaG3M1rrSni0Pn93S5ucSddMELsRF1QNm/f7/+4i/+Ivx+xYoVkqSlS5dq48aN+ru/+zudPn1aDzzwgDo7O/WNb3xDNTU1ysr6w6zyl19+WcuXL9fcuXOVlpamxYsX69lnn41BdwDALtzC6Fs0e7okcxDD1XMYY5JuNlIgEJDL5ZLf75fT6Ux0OQDQp0vdwgiNByT6FkY8Rnb6a2vDJ3poc8MV2z2zZJoWTfty/AvCoIjm85uHBQJAHNh+CyPRIzvs6YIrSYplxgCQbGzelt6GBw7a+rwj2IOAAgBxYOu29LY8cHCo7umC2CGgAEAc2HoLw6aRndCeLm5X5N+B25WV8Pk5SDzmoABAHNi6Lb1tIztDZU8XxB4BBQDiIHQLo/KlA3JIESElkbcwbBzZSfY9XRAf3OIBgDix8RYGk1ORLBhBAYA4su0Whq0jO8CF2KgNAFJQovdBQWpiozYAwGXZNrIDXIiAAgApismpsBmTZAEAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANYhoAAAAOsQUAAAgHUIKAAAwDoEFAAAYB0CCgAAsA4BBQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOsMSXYBNWj79TBXP1Onzs0GNGJ6mmoe+qaKxIxNdFgAAKSehIyjPPfecvvKVrygrK0uzZs3S3r17E1bLhMfe0Jwfv6XPzgZlJH12Nqg5P35LEx57I2E1AQCQqhIWUP7lX/5FK1as0Nq1a3XgwAFNnTpV5eXlam9vH/RaJjz2hs4F+z53LihCCgAAgyxhAeUnP/mJli1bpvvuu08lJSXasGGDRo4cqV/96leDWkfLp59dMpyEnAuebwcAAAZHQgLKmTNnVF9fr7Kysj8UkpamsrIyeb3ei9r39PQoEAhEvGKl4pm6mLYDAAADl5CA8umnn6q3t1d5eXkRx/Py8uTz+S5qX11dLZfLFX4VFhbGrJbPz15h+CTKdgAAYOCSYpnx6tWr5ff7w69jx47F7HuPGN6/v4L+tgMAAAOXkE/dsWPHKj09XW1tbRHH29ra5Ha7L2qfmZkpp9MZ8YqVmoe+GdN2AABg4BISUDIyMjRjxgzV1taGjwWDQdXW1srj8QxqLUVjR2rYFf4WhqWJ/VAAABhECbtvsWLFCv3iF7/Qiy++qA8//FCVlZU6ffq07rvvvkGv5ciTCy4ZUoalnT8PAAAGT8J2kr3jjjt04sQJrVmzRj6fT9OmTVNNTc1FE2cHy5EnF7CTLAAAlnAYY0yii4hWIBCQy+WS3++P6XwUAAAQP9F8frM0BQAAWIeAAgAArENAAQAA1iGgAAAA6xBQAACAdQgoAADAOgQUAABgHQIKAACwDgEFAABYJ2Fb3Q9EaPPbQCCQ4EoAAEB/hT63+7OJfVIGlK6uLklSYWFhgisBAADR6urqksvlumybpHwWTzAY1PHjxzV69Gg5HI6Yfu9AIKDCwkIdO3ZsyD/nh74OTanUVym1+ktfh65U6a8xRl1dXSooKFBa2uVnmSTlCEpaWprGjx8f15/hdDqH9C/JF9HXoSmV+iqlVn/p69CVCv290shJCJNkAQCAdQgoAADAOgSUC2RmZmrt2rXKzMxMdClxR1+HplTqq5Ra/aWvQ1eq9bc/knKSLAAAGNoYQQEAANYhoAAAAOsQUAAAgHUIKAAAwDoElC947rnn9JWvfEVZWVmaNWuW9u7dm+iSBuwf/uEf5HA4Il6TJk0Kn+/u7lZVVZXGjBmjUaNGafHixWpra0tgxdF5++23tXDhQhUUFMjhcOj111+POG+M0Zo1a5Sfn68RI0aorKxMH3/8cUSbjo4O3XXXXXI6ncrOztb999+vU6dODWIv+udKff3Od75z0bWuqKiIaJMsfa2urtbXvvY1jR49Wrm5ubr11lvV1NQU0aY/v7stLS1asGCBRo4cqdzcXK1cuVLnzp0bzK5cUX/6+ud//ucXXdvvfve7EW2Soa/r16/XlClTwpuReTwe7dixI3x+qFzTkCv1d6hc17gxMMYYs3nzZpORkWF+9atfmUOHDplly5aZ7Oxs09bWlujSBmTt2rXmj//4j01ra2v4deLEifD57373u6awsNDU1taa/fv3m9mzZ5s//dM/TWDF0XnzzTfN3//935vXXnvNSDJbtmyJOP/UU08Zl8tlXn/9dfNf//Vf5i//8i9NcXGx+fzzz8NtKioqzNSpU817771n/vM//9NMmDDB3HnnnYPckyu7Ul+XLl1qKioqIq51R0dHRJtk6Wt5ebl54YUXTGNjo2loaDDf+ta3TFFRkTl16lS4zZV+d8+dO2dKS0tNWVmZef/9982bb75pxo4da1avXp2ILl1Sf/r6zW9+0yxbtizi2vr9/vD5ZOnrv/3bv5k33njD/Pd//7dpamoyjz32mBk+fLhpbGw0xgydaxpypf4OlesaLwSU/zdz5kxTVVUVft/b22sKCgpMdXV1AqsauLVr15qpU6f2ea6zs9MMHz7cvPrqq+FjH374oZFkvF7vIFUYOxd+aAeDQeN2u82PfvSj8LHOzk6TmZlpXnnlFWOMMYcPHzaSzL59+8JtduzYYRwOh/nkk08GrfZoXSqgLFq06JJfk6x9NcaY9vZ2I8nU1dUZY/r3u/vmm2+atLQ04/P5wm3Wr19vnE6n6enpGdwOROHCvhpz/oPsoYceuuTXJGtfjTHmS1/6kvnlL385pK/pF4X6a8zQvq6xwC0eSWfOnFF9fb3KysrCx9LS0lRWViav15vAymLj448/VkFBga677jrdddddamlpkSTV19fr7NmzEf2eNGmSioqKhkS/m5ub5fP5Ivrncrk0a9ascP+8Xq+ys7P11a9+NdymrKxMaWlp2rNnz6DXPFC7d+9Wbm6uJk6cqMrKSp08eTJ8Lpn76vf7JUk5OTmS+ve76/V6NXnyZOXl5YXblJeXKxAI6NChQ4NYfXQu7GvIyy+/rLFjx6q0tFSrV6/WZ599Fj6XjH3t7e3V5s2bdfr0aXk8niF9TaWL+xsy1K5rLCXlwwJj7dNPP1Vvb2/EL4Ek5eXl6aOPPkpQVbExa9Ysbdy4URMnTlRra6vWrVunP/uzP1NjY6N8Pp8yMjKUnZ0d8TV5eXny+XyJKTiGQn3o67qGzvl8PuXm5kacHzZsmHJycpLu76CiokK33XabiouLdfToUT322GOaP3++vF6v0tPTk7avwWBQDz/8sL7+9a+rtLRUkvr1u+vz+fq89qFzNuqrr5L0V3/1V7r22mtVUFCgDz74QKtWrVJTU5Nee+01ScnV14MHD8rj8ai7u1ujRo3Sli1bVFJSooaGhiF5TS/VX2loXdd4IKAMcfPnzw//ecqUKZo1a5auvfZa/eu//qtGjBiRwMoQa0uWLAn/efLkyZoyZYquv/567d69W3Pnzk1gZQNTVVWlxsZGvfPOO4kuJe4u1dcHHngg/OfJkycrPz9fc+fO1dGjR3X99dcPdpkDMnHiRDU0NMjv9+s3v/mNli5dqrq6ukSXFTeX6m9JScmQuq7xwC0eSWPHjlV6evpFs8Xb2trkdrsTVFV8ZGdn64/+6I905MgRud1unTlzRp2dnRFthkq/Q3243HV1u91qb2+POH/u3Dl1dHQk/d/Bddddp7Fjx+rIkSOSkrOvy5cv1/bt2/XWW29p/Pjx4eP9+d11u919XvvQOdtcqq99mTVrliRFXNtk6WtGRoYmTJigGTNmqLq6WlOnTtUzzzwzJK+pdOn+9iWZr2s8EFB0/hdoxowZqq2tDR8LBoOqra2NuFc4FJw6dUpHjx5Vfn6+ZsyYoeHDh0f0u6mpSS0tLUOi38XFxXK73RH9CwQC2rNnT7h/Ho9HnZ2dqq+vD7fZtWuXgsFg+D8Wyep///d/dfLkSeXn50tKrr4aY7R8+XJt2bJFu3btUnFxccT5/vzuejweHTx4MCKU7dy5U06nMzzEboMr9bUvDQ0NkhRxbZOhr30JBoPq6ekZUtf0ckL97ctQuq4xkehZurbYvHmzyczMNBs3bjSHDx82DzzwgMnOzo6YPZ2MHn30UbN7927T3Nxsfve735mysjIzduxY097ebow5v6yvqKjI7Nq1y+zfv994PB7j8XgSXHX/dXV1mffff9+8//77RpL5yU9+Yt5//33z+9//3hhzfplxdna22bp1q/nggw/MokWL+lxm/Cd/8idmz5495p133jE33HCDlUtvL9fXrq4u87d/+7fG6/Wa5uZm8x//8R9m+vTp5oYbbjDd3d3h75Esfa2srDQul8vs3r07YgnmZ599Fm5zpd/d0BLNefPmmYaGBlNTU2PGjRtn3RLNK/X1yJEj5oknnjD79+83zc3NZuvWrea6664zc+bMCX+PZOnr97//fVNXV2eam5vNBx98YL7//e8bh8Nh/v3f/90YM3Suacjl+juUrmu8EFC+4Oc//7kpKioyGRkZZubMmea9995LdEkDdscdd5j8/HyTkZFhvvzlL5s77rjDHDlyJHz+888/N9/73vfMl770JTNy5Ejz7W9/27S2tiaw4ui89dZbRtJFr6VLlxpjzi81/sEPfmDy8vJMZmammTt3rmlqaor4HidPnjR33nmnGTVqlHE6nea+++4zXV1dCejN5V2ur5999pmZN2+eGTdunBk+fLi59tprzbJlyy4K2MnS1776Kcm88MIL4Tb9+d39n//5HzN//nwzYsQIM3bsWPPoo4+as2fPDnJvLu9KfW1paTFz5swxOTk5JjMz00yYMMGsXLkyYr8MY5Kjr3/9139trr32WpORkWHGjRtn5s6dGw4nxgydaxpyuf4OpesaLw5jjBm88RoAAIArYw4KAACwDgEFAABYh4ACAACsQ0ABAADWIaAAAADrEFAAAIB1CCgAAMA6BBQAAGAdAgoAALAOAQUAAFiHgAIAAKxDQAEAANb5P6nXm2TIUmqHAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "data = train_data_frame_list[0]\n",
    "num_features = len(data.columns)\n",
    "\n",
    "ax.scatter(data.iloc[0, range(0,num_features,3)], data.iloc[0, range(1,num_features,3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_frame_list = []\n",
    "for index in range(len(test_file_names)):\n",
    "    with open(os.path.join(test_path, test_file_names[index]), \"r\") as f:\n",
    "        content = f.readlines()\n",
    "        test_data_frame_list.append(pd.DataFrame([[float(p) for p in st.split(',')] for st in content[:len(content) // 2]]))\n",
    "        test_data_frame_list[-1].columns = [str(i) for i in range(len(test_data_frame_list[-1].columns))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2, 75, 3):\n",
    "    for df in train_data_frame_list:\n",
    "        df.loc[df[str(i)] == 0, [str(i-2), str(i-1)]] = np.nan\n",
    "\n",
    "if len(eval_data_frame_list) > 0:\n",
    "    for i in range(2, 75, 3):\n",
    "        for df in eval_data_frame_list:\n",
    "            df.loc[df[str(i)] == 0, [str(i-2), str(i-1)]] = np.nan\n",
    "\n",
    "for i in range(2, 75, 3):\n",
    "    for df in test_data_frame_list:\n",
    "        df.loc[df[str(i)] == 0, [str(i-2), str(i-1)]] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame = pd.concat(train_data_frame_list)\n",
    "train_data_frame = train_data_frame.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nose         2 114\n",
      "Neck         5 3\n",
      "R Shoulder   8 5\n",
      "R_Elbow      11 47\n",
      "R_Wrist      14 558\n",
      "L_Shoulder   17 5\n",
      "L_Elbow      20 31\n",
      "L_Wrist      23 575\n",
      "M_Hip        26 6\n",
      "R_Hip        29 14\n",
      "R_Nee        32 210746\n",
      "R_Ankle      35 261418 dropped\n",
      "L_Hip        38 13\n",
      "L_Nee        41 204473\n",
      "L_Ankle      44 261454 dropped\n",
      "R_Eye        47 247\n",
      "L_Eye        50 162\n",
      "R_Ear        53 20836\n",
      "L_Ear        56 20958\n",
      "L_Big_Toe    59 261460 dropped\n",
      "L_Small_Toe  62 261461 dropped\n",
      "L_Heel       65 261458 dropped\n",
      "R_Big_Toe    68 261457 dropped\n",
      "R_Small_Toe  71 261457 dropped\n",
      "R_Heel       74 261460 dropped\n"
     ]
    }
   ],
   "source": [
    "idx_maping = {2: \"Nose\", 5: \"Neck\", 8: \"R Shoulder\", 11: \"R_Elbow\", 14: \"R_Wrist\", 17: \"L_Shoulder\", \n",
    "            20: \"L_Elbow\", 23: \"L_Wrist\", 26: \"M_Hip\", 29: \"R_Hip\", 32: \"R_Nee\", 35: \"R_Ankle\", 38: \"L_Hip\", \n",
    "            41: \"L_Nee\", 44: \"L_Ankle\", 47: \"R_Eye\", 50: \"L_Eye\", 53: \"R_Ear\", 56: \"L_Ear\", 59: \"L_Big_Toe\", \n",
    "            62: \"L_Small_Toe\", 65: \"L_Heel\", 68: \"R_Big_Toe\", 71: \"R_Small_Toe\", 74: \"R_Heel\"}\n",
    "\n",
    "for i in range(2, 75, 3):\n",
    "    l = len(train_data_frame.loc[train_data_frame[str(i)] == 0])\n",
    "    if (l > 0.9 * len(train_data_frame)):\n",
    "        for df in train_data_frame_list:\n",
    "            df.drop([str(i-2), str(i-1)], axis=1, inplace=True)\n",
    "        if len(eval_data_frame_list) > 0:\n",
    "            for df in eval_data_frame_list:\n",
    "                df.drop([str(i-2), str(i-1)], axis=1, inplace=True)\n",
    "        for df in test_data_frame_list:\n",
    "            df.drop([str(i-2), str(i-1)], axis=1, inplace=True)\n",
    "        print(idx_maping[i], \" \" * (11 - len(idx_maping[i])), i, l, \"dropped\")\n",
    "    else:\n",
    "        print(idx_maping[i], \" \" * (11 - len(idx_maping[i])), i, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>253.674301</td>\n",
       "      <td>102.96611</td>\n",
       "      <td>269.803192</td>\n",
       "      <td>191.368973</td>\n",
       "      <td>201.43306</td>\n",
       "      <td>201.431473</td>\n",
       "      <td>181.371231</td>\n",
       "      <td>305.924591</td>\n",
       "      <td>169.328186</td>\n",
       "      <td>398.415344</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.681686</td>\n",
       "      <td>89.026604</td>\n",
       "      <td>267.719818</td>\n",
       "      <td>86.884895</td>\n",
       "      <td>221.565857</td>\n",
       "      <td>106.978127</td>\n",
       "      <td>295.942169</td>\n",
       "      <td>92.969368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>201.00000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>172.000000</td>\n",
       "      <td>395.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>201.00000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>175.000000</td>\n",
       "      <td>391.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253.000000</td>\n",
       "      <td>102.00000</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>202.00000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>387.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254.000000</td>\n",
       "      <td>101.00000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>203.00000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>302.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>383.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>269.000000</td>\n",
       "      <td>86.00000</td>\n",
       "      <td>291.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>215.00000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>196.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>252.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>273.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>219.00000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>376.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>277.000000</td>\n",
       "      <td>85.00000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>223.00000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>385.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>293.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>282.000000</td>\n",
       "      <td>84.00000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>230.00000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>397.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>298.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>287.000000</td>\n",
       "      <td>83.00000</td>\n",
       "      <td>310.000000</td>\n",
       "      <td>182.000000</td>\n",
       "      <td>235.00000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           3           4          6           7  \\\n",
       "0    253.674301  102.96611  269.803192  191.368973  201.43306  201.431473   \n",
       "1    253.000000  102.00000  270.000000  191.000000  201.00000  202.000000   \n",
       "2    253.000000  102.00000  272.000000  189.000000  201.00000  203.000000   \n",
       "3    253.000000  102.00000  272.000000  189.000000  202.00000  204.000000   \n",
       "4    254.000000  101.00000  273.000000  189.000000  203.00000  204.000000   \n",
       "..          ...        ...         ...         ...        ...         ...   \n",
       "217  269.000000   86.00000  291.000000  182.000000  215.00000  193.000000   \n",
       "218  273.000000   85.00000  295.000000  182.000000  219.00000  193.000000   \n",
       "219  277.000000   85.00000  300.000000  182.000000  223.00000  191.000000   \n",
       "220  282.000000   84.00000  305.000000  182.000000  230.00000  190.000000   \n",
       "221  287.000000   83.00000  310.000000  182.000000  235.00000  189.000000   \n",
       "\n",
       "              9          10          12          13  ...  39  40          45  \\\n",
       "0    181.371231  305.924591  169.328186  398.415344  ... NaN NaN  235.681686   \n",
       "1    181.000000  305.000000  172.000000  395.000000  ... NaN NaN  235.000000   \n",
       "2    181.000000  304.000000  175.000000  391.000000  ... NaN NaN  235.000000   \n",
       "3    182.000000  303.000000  178.000000  387.000000  ... NaN NaN  235.000000   \n",
       "4    184.000000  302.000000  182.000000  383.000000  ... NaN NaN  235.000000   \n",
       "..          ...         ...         ...         ...  ...  ..  ..         ...   \n",
       "217  196.000000  292.000000  178.000000  365.000000  ... NaN NaN  252.000000   \n",
       "218  199.000000  293.000000  181.000000  376.000000  ... NaN NaN  256.000000   \n",
       "219  202.000000  294.000000  184.000000  385.000000  ... NaN NaN  262.000000   \n",
       "220  204.000000  297.000000  187.000000  397.000000  ... NaN NaN  267.000000   \n",
       "221  208.000000  299.000000  189.000000  407.000000  ... NaN NaN  272.000000   \n",
       "\n",
       "            46          48         49          51          52          54  \\\n",
       "0    89.026604  267.719818  86.884895  221.565857  106.978127  295.942169   \n",
       "1    89.000000  267.000000  86.000000  221.000000  107.000000  296.000000   \n",
       "2    89.000000  267.000000  86.000000  221.000000  107.000000  296.000000   \n",
       "3    89.000000  267.000000  86.000000  221.000000  107.000000  296.000000   \n",
       "4    89.000000  268.000000  85.000000  221.000000  107.000000  297.000000   \n",
       "..         ...         ...        ...         ...         ...         ...   \n",
       "217  78.000000  285.000000  69.000000  239.000000   96.000000  316.000000   \n",
       "218  77.000000  289.000000  68.000000  243.000000   95.000000  317.000000   \n",
       "219  75.000000  293.000000  68.000000  247.000000   95.000000  321.000000   \n",
       "220  74.000000  298.000000  67.000000  251.000000   94.000000  326.000000   \n",
       "221  73.000000  303.000000  69.000000  256.000000   93.000000  331.000000   \n",
       "\n",
       "            55  \n",
       "0    92.969368  \n",
       "1    93.000000  \n",
       "2    92.000000  \n",
       "3    92.000000  \n",
       "4    91.000000  \n",
       "..         ...  \n",
       "217  85.000000  \n",
       "218  84.000000  \n",
       "219  84.000000  \n",
       "220  84.000000  \n",
       "221  84.000000  \n",
       "\n",
       "[222 rows x 34 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for df in train_data_frame_list:\n",
    "    df.drop([str(i) for i in range(2, 75, 3)], axis=1, inplace=True)\n",
    "for df in eval_data_frame_list:\n",
    "    df.drop([str(i) for i in range(2, 75, 3)], axis=1, inplace=True)\n",
    "for df in test_data_frame_list:\n",
    "    df.drop([str(i) for i in range(2, 75, 3)], axis=1, inplace=True)\n",
    "\n",
    "train_data_frame_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = len(train_data_frame_list[0].columns)\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.128891</td>\n",
       "      <td>-88.402863</td>\n",
       "      <td>-68.370132</td>\n",
       "      <td>10.0625</td>\n",
       "      <td>-88.431961</td>\n",
       "      <td>114.555618</td>\n",
       "      <td>-100.475006</td>\n",
       "      <td>207.046371</td>\n",
       "      <td>72.329865</td>\n",
       "      <td>-8.064682</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-34.121506</td>\n",
       "      <td>-102.342369</td>\n",
       "      <td>-2.083374</td>\n",
       "      <td>-104.484077</td>\n",
       "      <td>221.565857</td>\n",
       "      <td>106.978127</td>\n",
       "      <td>295.942169</td>\n",
       "      <td>92.969368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-17.000000</td>\n",
       "      <td>-89.000000</td>\n",
       "      <td>-69.000000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>-89.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>-102.000000</td>\n",
       "      <td>-3.000000</td>\n",
       "      <td>-105.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-87.000000</td>\n",
       "      <td>-71.000000</td>\n",
       "      <td>14.0000</td>\n",
       "      <td>-91.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-103.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-87.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-103.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-19.000000</td>\n",
       "      <td>-88.000000</td>\n",
       "      <td>-70.000000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>-89.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>-91.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-5.000000</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>221.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>297.000000</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>-76.000000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>-95.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-104.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-22.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-76.000000</td>\n",
       "      <td>11.0000</td>\n",
       "      <td>-96.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-105.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>317.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>-77.000000</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>-116.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-107.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>247.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>321.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>8.0000</td>\n",
       "      <td>-101.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-108.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-115.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-99.000000</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>-102.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>-121.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>-11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-38.000000</td>\n",
       "      <td>-109.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>331.000000</td>\n",
       "      <td>84.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1          6        7           9          10  \\\n",
       "0   -16.128891 -88.402863 -68.370132  10.0625  -88.431961  114.555618   \n",
       "1   -17.000000 -89.000000 -69.000000  11.0000  -89.000000  114.000000   \n",
       "2   -19.000000 -87.000000 -71.000000  14.0000  -91.000000  115.000000   \n",
       "3   -19.000000 -87.000000 -70.000000  15.0000  -90.000000  114.000000   \n",
       "4   -19.000000 -88.000000 -70.000000  15.0000  -89.000000  113.000000   \n",
       "..         ...        ...        ...      ...         ...         ...   \n",
       "217 -22.000000 -96.000000 -76.000000  11.0000  -95.000000  110.000000   \n",
       "218 -22.000000 -97.000000 -76.000000  11.0000  -96.000000  111.000000   \n",
       "219 -23.000000 -97.000000 -77.000000   9.0000  -98.000000  112.000000   \n",
       "220 -23.000000 -98.000000 -75.000000   8.0000 -101.000000  115.000000   \n",
       "221 -23.000000 -99.000000 -75.000000   7.0000 -102.000000  117.000000   \n",
       "\n",
       "             12          13         15         16  ...  39  40         45  \\\n",
       "0   -100.475006  207.046371  72.329865  -8.064682  ... NaN NaN -34.121506   \n",
       "1    -98.000000  204.000000  72.000000  -8.000000  ... NaN NaN -35.000000   \n",
       "2    -97.000000  202.000000  70.000000  -6.000000  ... NaN NaN -37.000000   \n",
       "3    -94.000000  198.000000  70.000000  -6.000000  ... NaN NaN -37.000000   \n",
       "4    -91.000000  194.000000  69.000000  -7.000000  ... NaN NaN -38.000000   \n",
       "..          ...         ...        ...        ...  ...  ..  ..        ...   \n",
       "217 -113.000000  183.000000  74.000000 -12.000000  ... NaN NaN -39.000000   \n",
       "218 -114.000000  194.000000  74.000000 -12.000000  ... NaN NaN -39.000000   \n",
       "219 -116.000000  203.000000  74.000000 -12.000000  ... NaN NaN -38.000000   \n",
       "220 -118.000000  215.000000  74.000000 -12.000000  ... NaN NaN -38.000000   \n",
       "221 -121.000000  225.000000  75.000000 -11.000000  ... NaN NaN -38.000000   \n",
       "\n",
       "             46        48          49          51          52          54  \\\n",
       "0   -102.342369 -2.083374 -104.484077  221.565857  106.978127  295.942169   \n",
       "1   -102.000000 -3.000000 -105.000000  221.000000  107.000000  296.000000   \n",
       "2   -100.000000 -5.000000 -103.000000  221.000000  107.000000  296.000000   \n",
       "3   -100.000000 -5.000000 -103.000000  221.000000  107.000000  296.000000   \n",
       "4   -100.000000 -5.000000 -104.000000  221.000000  107.000000  297.000000   \n",
       "..          ...       ...         ...         ...         ...         ...   \n",
       "217 -104.000000 -6.000000 -113.000000  239.000000   96.000000  316.000000   \n",
       "218 -105.000000 -6.000000 -114.000000  243.000000   95.000000  317.000000   \n",
       "219 -107.000000 -7.000000 -114.000000  247.000000   95.000000  321.000000   \n",
       "220 -108.000000 -7.000000 -115.000000  251.000000   94.000000  326.000000   \n",
       "221 -109.000000 -7.000000 -113.000000  256.000000   93.000000  331.000000   \n",
       "\n",
       "            55  \n",
       "0    92.969368  \n",
       "1    93.000000  \n",
       "2    92.000000  \n",
       "3    92.000000  \n",
       "4    91.000000  \n",
       "..         ...  \n",
       "217  85.000000  \n",
       "218  84.000000  \n",
       "219  84.000000  \n",
       "220  84.000000  \n",
       "221  84.000000  \n",
       "\n",
       "[222 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##drop neck\n",
    "for df in train_data_frame_list:\n",
    "    df[df.columns[range(0, num_features-4, 2)]] = df[df.columns[range(0, num_features-4, 2)]].sub(df['3'], axis=0)\n",
    "    df[df.columns[range(1, num_features-4, 2)]] = df[df.columns[range(1, num_features-4, 2)]].sub(df['4'], axis=0)\n",
    "    df.drop(['3', '4'], axis=1, inplace=True)\n",
    "for df in eval_data_frame_list:\n",
    "    df[df.columns[range(0, num_features-4, 2)]] = df[df.columns[range(0, num_features-4, 2)]].sub(df['3'], axis=0)\n",
    "    df[df.columns[range(1, num_features-4, 2)]] = df[df.columns[range(1, num_features-4, 2)]].sub(df['4'], axis=0)\n",
    "    df.drop(['3', '4'], axis=1, inplace=True)\n",
    "for df in test_data_frame_list:\n",
    "    df[df.columns[range(0, num_features-4, 2)]] = df[df.columns[range(0, num_features-4, 2)]].sub(df['3'], axis=0)\n",
    "    df[df.columns[range(1, num_features-4, 2)]] = df[df.columns[range(1, num_features-4, 2)]].sub(df['4'], axis=0)\n",
    "    df.drop(['3', '4'], axis=1, inplace=True)\n",
    "train_data_frame_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame = pd.concat(train_data_frame_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = train_data_frame.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7      6.719224\n",
       "16     6.821346\n",
       "6      9.150496\n",
       "15     9.336125\n",
       "24    12.438516\n",
       "36    13.806552\n",
       "27    13.897407\n",
       "49    15.760351\n",
       "1     15.973130\n",
       "46    16.071189\n",
       "45    17.073184\n",
       "48    17.153954\n",
       "0     17.925844\n",
       "30    18.033851\n",
       "52    20.557677\n",
       "55    21.310782\n",
       "51    25.453274\n",
       "28    26.175731\n",
       "40    26.178947\n",
       "25    26.354030\n",
       "37    26.709450\n",
       "31    27.204049\n",
       "54    27.227389\n",
       "10    28.436968\n",
       "9     28.467797\n",
       "39    28.898984\n",
       "19    30.026997\n",
       "18    31.785149\n",
       "12    57.550179\n",
       "13    66.129667\n",
       "22    72.843093\n",
       "21    75.690933\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['9', '10', '12', '13', '18', '19', '21', '22'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_maping = {2: \"Nose\", 5: \"Neck\", 8: \"R Shoulder\", 11: \"R_Elbow\", 14: \"R_Wrist\", 17: \"L_Shoulder\", \n",
    "            20: \"L_Elbow\", 23: \"L_Wrist\", 26: \"M_Hip\", 29: \"R_Hip\", 32: \"R_Nee\", 35: \"R_Ankle\", 38: \"L_Hip\", \n",
    "            41: \"L_Nee\", 44: \"L_Ankle\", 47: \"R_Eye\", 50: \"L_Eye\", 53: \"R_Ear\", 56: \"L_Ear\", 59: \"L_Big_Toe\", \n",
    "            62: \"L_Small_Toe\", 65: \"L_Heel\", 68: \"R_Big_Toe\", 71: \"R_Small_Toe\", 74: \"R_Heel\"}\n",
    "columns = [4, 5, 6, 7, 10, 11, 12, 13]\n",
    "train_data_frame_list[0].columns[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-88.431961</td>\n",
       "      <td>114.555618</td>\n",
       "      <td>-100.475006</td>\n",
       "      <td>207.046371</td>\n",
       "      <td>110.491272</td>\n",
       "      <td>98.505539</td>\n",
       "      <td>108.544098</td>\n",
       "      <td>200.886093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-89.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>-98.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>197.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-91.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>-97.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-90.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>-94.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-89.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>-91.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>-95.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>-113.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>219.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>-96.000000</td>\n",
       "      <td>111.000000</td>\n",
       "      <td>-114.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>-98.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>-116.000000</td>\n",
       "      <td>203.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>226.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>-101.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>-118.000000</td>\n",
       "      <td>215.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>-102.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>-121.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>113.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>227.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>222 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              9          10          12          13          18          19  \\\n",
       "0    -88.431961  114.555618 -100.475006  207.046371  110.491272   98.505539   \n",
       "1    -89.000000  114.000000  -98.000000  204.000000  111.000000   98.000000   \n",
       "2    -91.000000  115.000000  -97.000000  202.000000  110.000000   98.000000   \n",
       "3    -90.000000  114.000000  -94.000000  198.000000  112.000000   96.000000   \n",
       "4    -89.000000  113.000000  -91.000000  194.000000  115.000000   93.000000   \n",
       "..          ...         ...         ...         ...         ...         ...   \n",
       "217  -95.000000  110.000000 -113.000000  183.000000  110.000000  104.000000   \n",
       "218  -96.000000  111.000000 -114.000000  194.000000  110.000000  109.000000   \n",
       "219  -98.000000  112.000000 -116.000000  203.000000  110.000000  112.000000   \n",
       "220 -101.000000  115.000000 -118.000000  215.000000  110.000000  114.000000   \n",
       "221 -102.000000  117.000000 -121.000000  225.000000  113.000000  114.000000   \n",
       "\n",
       "             21          22  \n",
       "0    108.544098  200.886093  \n",
       "1    106.000000  197.000000  \n",
       "2    104.000000  192.000000  \n",
       "3    103.000000  186.000000  \n",
       "4    101.000000  178.000000  \n",
       "..          ...         ...  \n",
       "217  103.000000  219.000000  \n",
       "218  110.000000  225.000000  \n",
       "219  114.000000  226.000000  \n",
       "220  120.000000  227.000000  \n",
       "221  125.000000  227.000000  \n",
       "\n",
       "[222 rows x 8 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_data_frame_list[0]\n",
    "df[['9', '10', '12', '13', '18', '19', '21', '22']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_train_data_list = []\n",
    "essential_eval_data_list = []\n",
    "essential_test_data_list = []\n",
    "for df in train_data_frame_list:\n",
    "    essential_train_data_list.append(df[df.columns[columns]])\n",
    "for df in eval_data_frame_list:\n",
    "    essential_eval_data_list.append(df[df.columns[columns]])\n",
    "for df in test_data_frame_list:\n",
    "    essential_test_data_list.append(df[df.columns[columns]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T06:27:42.674100Z",
     "iopub.status.busy": "2022-07-27T06:27:42.673648Z",
     "iopub.status.idle": "2022-07-27T06:27:42.760215Z",
     "shell.execute_reply": "2022-07-27T06:27:42.759185Z",
     "shell.execute_reply.started": "2022-07-27T06:27:42.674063Z"
    }
   },
   "outputs": [],
   "source": [
    "class Normalization():\n",
    "  def __init__(self, input):\n",
    "    self.mean = input.mean()\n",
    "    self.std = input.std()\n",
    "\n",
    "  def transform(self, data):\n",
    "    return (data - self.mean) / self.std\n",
    "\n",
    "normalization = Normalization(pd.concat(essential_train_data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.12250480e-02,  2.73506212e-03,  2.51820658e-01, ...,\n",
       "        -1.40248857e+00,  1.47370211e-01, -1.04672391e+00],\n",
       "       [-3.42723844e-02, -1.25044269e-02,  2.57386453e-01, ...,\n",
       "        -1.41106138e+00,  1.55472248e-01, -1.04669940e+00],\n",
       "       [-3.42723844e-02,  3.74315990e-01,  2.92138734e-01, ...,\n",
       "        -1.41106138e+00,  1.68683870e-01, -1.04669940e+00],\n",
       "       ...,\n",
       "       [ 8.55026876e-04, -4.76699193e-02,  6.04909262e-01, ...,\n",
       "        -1.44436474e+00,  2.08318737e-01, -1.06042754e+00],\n",
       "       [-3.42723844e-02, -8.28354118e-02,  5.18028560e-01, ...,\n",
       "        -1.44436474e+00,  2.08318737e-01, -1.06042754e+00],\n",
       "       [ 3.59824381e-02, -1.25044269e-02,  5.18028560e-01, ...,\n",
       "        -1.44436474e+00,  2.21530359e-01, -1.07415568e+00]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_normalized_data_list = []\n",
    "for df in essential_train_data_list:\n",
    "  train_normalized_data_list.append(np.nan_to_num(normalization.transform(df).values))\n",
    "  \n",
    "if len(eval_data_frame_list) > 0:\n",
    "    eval_normalized_data_list = []\n",
    "    for df in essential_eval_data_list:\n",
    "        eval_normalized_data_list.append(np.nan_to_num(normalization.transform(df).values))\n",
    "    eval_normalized_data_list[0]\n",
    "\n",
    "test_normalized_data_list = []\n",
    "for df in essential_test_data_list:\n",
    "    test_normalized_data_list.append(np.nan_to_num(normalization.transform(df).values))\n",
    "test_normalized_data_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T06:27:43.937231Z",
     "iopub.status.busy": "2022-07-27T06:27:43.936645Z",
     "iopub.status.idle": "2022-07-27T06:27:43.946682Z",
     "shell.execute_reply": "2022-07-27T06:27:43.945806Z",
     "shell.execute_reply.started": "2022-07-27T06:27:43.937193Z"
    }
   },
   "outputs": [],
   "source": [
    "class Create_Dataset(Dataset):\n",
    "  def __init__(self, data, time_length, sliding_step):\n",
    "    input = []\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for dt in range(len(data)):\n",
    "      name = train_file_names[dt]\n",
    "      label = mapping_labels[name[name.index('_')+1: name.index('.')]]\n",
    "      for i in range(0, len(data[dt]) - time_length + 1, sliding_step):\n",
    "        input.append(data[dt][i:i+time_length])\n",
    "        labels.append(label)\n",
    "        \n",
    "    self.data =  torch.from_numpy(np.stack(input)) # Shape = [num_samples, time_length, features]\n",
    "    self.labels = torch.tensor(labels) # Shape = [num_samples]\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.data[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T06:27:43.950013Z",
     "iopub.status.busy": "2022-07-27T06:27:43.949721Z",
     "iopub.status.idle": "2022-07-27T06:27:44.471814Z",
     "shell.execute_reply": "2022-07-27T06:27:44.470895Z",
     "shell.execute_reply.started": "2022-07-27T06:27:43.949990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 90, 8])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define time_length, sliding_step and batch_size\n",
    "time_length = 90 \n",
    "sliding_step = time_length // 2\n",
    "batch_size = 30\n",
    "dataset = Create_Dataset(train_normalized_data_list, time_length, sliding_step)\n",
    "dl_train = DataLoader(dataset, batch_size, shuffle=True)\n",
    "next(iter(dl_train))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluation():\n",
    "  def __init__(self):\n",
    "    self.eval_data = []\n",
    "    self.labels = []\n",
    "    for dt in range(len(eval_normalized_data_list)):\n",
    "      name = eval_file_names[dt]\n",
    "      label = mapping_labels[name[name.index('_')+1: name.index('.')]]\n",
    "      data = []\n",
    "      for i in range(0, len(eval_normalized_data_list[dt]) - time_length + 1, sliding_step):\n",
    "        data.append(eval_normalized_data_list[dt][i:i+time_length])\n",
    "      self.eval_data.append(torch.from_numpy(np.stack(data)))\n",
    "      self.labels.append(label)\n",
    "      \n",
    "  def eval(self, model, type=\"RNN\"):\n",
    "    model.eval()\n",
    "    count = 0\n",
    "    for i in range(len(self.eval_data)):\n",
    "      if type == 'RNN':\n",
    "        prediction = model(self.eval_data[i].to(device))\n",
    "      else:\n",
    "        prediction = model(self.eval_data[i].unsqueeze(1).to(device))\n",
    "      pre = prediction.argmax(dim=1)\n",
    "      if pre.bincount().argmax().item() == self.labels[i]:\n",
    "        count += 1\n",
    "\n",
    "    return 0 if len(self.eval_data) == 0 else count/len(self.eval_data)\n",
    "\n",
    "evaluation = Evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Training\n",
    "The function below is used to train a model. The learning rate is reduced during the training to achieve a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T06:27:44.473815Z",
     "iopub.status.busy": "2022-07-27T06:27:44.473247Z",
     "iopub.status.idle": "2022-07-27T06:27:44.488629Z",
     "shell.execute_reply": "2022-07-27T06:27:44.487564Z",
     "shell.execute_reply.started": "2022-07-27T06:27:44.473778Z"
    }
   },
   "outputs": [],
   "source": [
    "def Train_Model(model, model_type='RNN', learning_rate=0.1):\n",
    "    # use CrossEntropyLoss for classification problem\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    # use SGD optimization\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    eval_accuracies = []\n",
    "    best_loss = float('inf')\n",
    "    best_model = model\n",
    "    lr_idx = 0\n",
    "    epoch = 0\n",
    "    while learning_rate >= 1e-3:\n",
    "        epoch += 1\n",
    "        # set the model in training mode      \n",
    "        model.train()\n",
    "        train_loss, train_acc = 0., 0.\n",
    "        for batch in dl_train:            \n",
    "            # send the input to the device\n",
    "            x_batch, y_batch = batch[0].to(device), batch[1].to(device)\n",
    "            if model_type == 'CNN':\n",
    "                x_batch = x_batch.unsqueeze(1) # change size to [num_batch, channel, height, width]\n",
    "            # perform a forward pass and calculate the training loss\n",
    "            predictions = model(x_batch)\n",
    "            l = loss(predictions, y_batch)\n",
    "\n",
    "            # zero out the gradients, perform the backpropagation step, and update the weights\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += l.item()*len(x_batch)\n",
    "            train_acc += (predictions.argmax(dim=1) == y_batch).type(torch.float).sum().item()\n",
    "\n",
    "        \n",
    "        eval_acc = evaluation.eval(model, model_type)*100\n",
    "        eval_accuracies.append(eval_acc)\n",
    "\n",
    "        train_loss /= len(dl_train.dataset)\n",
    "        train_acc /= len(dl_train.dataset)/100.\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "                  \n",
    "        print(f\"Epoch {'{:03d}'.format(epoch)} - Training loss: {'{:.3f}'.format(train_loss)} - Training accuracy: {'{:.2f}'.format(train_acc)}% - Eval accuracy: {'{:.2f}'.format(eval_acc)}% - Learning rate: {learning_rate}\")\n",
    "\n",
    "        # save the best model\n",
    "        if (best_loss > train_loss):\n",
    "            best_loss = train_loss\n",
    "            best_model = model\n",
    "            lr_idx = epoch\n",
    "        \n",
    "        # reduce the learning rate, if the loss has not reduced in the past epochs\n",
    "        if lr_idx + 3 <= epoch:\n",
    "            learning_rate /= 2.\n",
    "            optimizer.param_groups[0]['lr'] = learning_rate\n",
    "            lr_idx = epoch\n",
    "            model = best_model\n",
    "            \n",
    "    # plot training loss and accuracy\n",
    "    \n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(3, 1)\n",
    "    fig.subplots_adjust(wspace = 0.3)\n",
    "    ax0.plot(range(1, epoch+1), train_losses, 'blue')\n",
    "    ax0.set_xlabel('Epoch')\n",
    "    ax0.set_ylabel('Loss')\n",
    "    ax0.set_title(\"Training losses\")\n",
    "    ax1.plot(range(1, epoch+1), train_accuracies, 'orange')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_title(\"Training accuracies\")\n",
    "    ax2.plot(range(1, epoch+1), eval_accuracies, 'orange')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_title(\"Eval accuracies\")\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = train_normalized_data_list[0].shape[1]\n",
    "num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN_NET(\n",
      "  (rnn): LSTM(8, 32, batch_first=True)\n",
      "  (net): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Dropout(p=0.2, inplace=False)\n",
      "    (2): Linear(in_features=2880, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Dropout(p=0.2, inplace=False)\n",
      "    (5): Linear(in_features=128, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class RNN_NET(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()        \n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.net = nn.Sequential(nn.Flatten(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(time_length*hidden_dim, 128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(128, num_categories))        \n",
    "    def forward(self, X):\n",
    "        hidden_output, _ = self.rnn(X)\n",
    "        output = self.net(hidden_output)\n",
    "        return output\n",
    "    \n",
    "rnn_model = RNN_NET(input_dim=num_features, hidden_dim=32).double().to(device)\n",
    "print(rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1472])\n",
      "CNN_NET(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Conv2d(16, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
      "    (5): ReLU()\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Dropout(p=0.2, inplace=False)\n",
      "    (8): Flatten(start_dim=1, end_dim=-1)\n",
      "    (9): Linear(in_features=1472, out_features=64, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Dropout(p=0.2, inplace=False)\n",
      "    (12): Linear(in_features=64, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN_NET(nn.Module):\n",
    "  def __init__(self, height, width):\n",
    "    super().__init__()\n",
    "        \n",
    "    self.net = nn.Sequential(nn.Conv2d(1, 16, kernel_size=2, padding=1),\n",
    "                             nn.ReLU(),\n",
    "                             nn.MaxPool2d(kernel_size=2),\n",
    "                             nn.Dropout(0.2),\n",
    "                             nn.Conv2d(16, 32, kernel_size=2, padding=1),\n",
    "                             nn.ReLU(),\n",
    "                             nn.MaxPool2d(kernel_size=2),\n",
    "                             nn.Dropout(0.2),\n",
    "                             nn.Flatten())\n",
    "    \n",
    "    x = self.net(torch.rand(1, 1, height, width))\n",
    "    print(x.shape)\n",
    "    self.net.append(nn.Linear(x.shape[1], 64))\n",
    "    self.net.append(nn.ReLU())\n",
    "    self.net.append(nn.Dropout(0.2))\n",
    "    self.net.append(nn.Linear(64, num_categories))\n",
    "  def forward(self, x):\n",
    "    return self.net(x)\n",
    "\n",
    "cnn_model = CNN_NET(height=time_length, width=num_features).double().to(device)\n",
    "print(cnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 - Training loss: 0.543 - Training accuracy: 79.62% - Eval accuracy: 93.04% - Learning rate: 0.1\n",
      "Epoch 002 - Training loss: 0.145 - Training accuracy: 95.01% - Eval accuracy: 93.48% - Learning rate: 0.1\n",
      "Epoch 003 - Training loss: 0.093 - Training accuracy: 96.95% - Eval accuracy: 97.83% - Learning rate: 0.1\n",
      "Epoch 004 - Training loss: 0.055 - Training accuracy: 98.18% - Eval accuracy: 97.39% - Learning rate: 0.1\n",
      "Epoch 005 - Training loss: 0.053 - Training accuracy: 98.27% - Eval accuracy: 97.83% - Learning rate: 0.1\n",
      "Epoch 006 - Training loss: 0.034 - Training accuracy: 99.00% - Eval accuracy: 98.26% - Learning rate: 0.1\n",
      "Epoch 007 - Training loss: 0.021 - Training accuracy: 99.20% - Eval accuracy: 97.83% - Learning rate: 0.1\n",
      "Epoch 008 - Training loss: 0.020 - Training accuracy: 99.38% - Eval accuracy: 97.39% - Learning rate: 0.1\n",
      "Epoch 009 - Training loss: 0.017 - Training accuracy: 99.57% - Eval accuracy: 98.26% - Learning rate: 0.1\n",
      "Epoch 010 - Training loss: 0.009 - Training accuracy: 99.79% - Eval accuracy: 98.70% - Learning rate: 0.1\n",
      "Epoch 011 - Training loss: 0.018 - Training accuracy: 99.43% - Eval accuracy: 99.13% - Learning rate: 0.1\n",
      "Epoch 012 - Training loss: 0.007 - Training accuracy: 99.86% - Eval accuracy: 98.70% - Learning rate: 0.1\n",
      "Epoch 013 - Training loss: 0.004 - Training accuracy: 99.95% - Eval accuracy: 99.13% - Learning rate: 0.1\n",
      "Epoch 014 - Training loss: 0.005 - Training accuracy: 99.89% - Eval accuracy: 99.13% - Learning rate: 0.1\n",
      "Epoch 015 - Training loss: 0.004 - Training accuracy: 99.95% - Eval accuracy: 98.70% - Learning rate: 0.1\n",
      "Epoch 016 - Training loss: 0.003 - Training accuracy: 99.98% - Eval accuracy: 98.70% - Learning rate: 0.1\n",
      "Epoch 017 - Training loss: 0.004 - Training accuracy: 99.93% - Eval accuracy: 99.13% - Learning rate: 0.1\n",
      "Epoch 018 - Training loss: 0.021 - Training accuracy: 99.43% - Eval accuracy: 97.83% - Learning rate: 0.1\n",
      "Epoch 019 - Training loss: 0.018 - Training accuracy: 99.54% - Eval accuracy: 98.70% - Learning rate: 0.1\n",
      "Epoch 020 - Training loss: 0.003 - Training accuracy: 100.00% - Eval accuracy: 98.26% - Learning rate: 0.05\n",
      "Epoch 021 - Training loss: 0.004 - Training accuracy: 99.91% - Eval accuracy: 99.13% - Learning rate: 0.05\n",
      "Epoch 022 - Training loss: 0.002 - Training accuracy: 99.98% - Eval accuracy: 99.13% - Learning rate: 0.05\n",
      "Epoch 023 - Training loss: 0.002 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.05\n",
      "Epoch 024 - Training loss: 0.002 - Training accuracy: 99.98% - Eval accuracy: 99.13% - Learning rate: 0.05\n",
      "Epoch 025 - Training loss: 0.002 - Training accuracy: 100.00% - Eval accuracy: 98.70% - Learning rate: 0.05\n",
      "Epoch 026 - Training loss: 0.002 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.05\n",
      "Epoch 027 - Training loss: 0.002 - Training accuracy: 99.98% - Eval accuracy: 99.13% - Learning rate: 0.05\n",
      "Epoch 028 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 029 - Training loss: 0.002 - Training accuracy: 99.95% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 030 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 031 - Training loss: 0.001 - Training accuracy: 99.98% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 032 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 033 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 034 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 035 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 036 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 037 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 038 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 039 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.57% - Learning rate: 0.025\n",
      "Epoch 040 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.025\n",
      "Epoch 041 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 042 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 043 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 044 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 045 - Training loss: 0.001 - Training accuracy: 99.98% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 046 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 047 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0125\n",
      "Epoch 048 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.00625\n",
      "Epoch 049 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.00625\n",
      "Epoch 050 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.00625\n",
      "Epoch 051 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.003125\n",
      "Epoch 052 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.003125\n",
      "Epoch 053 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.003125\n",
      "Epoch 054 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0015625\n",
      "Epoch 055 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0015625\n",
      "Epoch 056 - Training loss: 0.001 - Training accuracy: 100.00% - Eval accuracy: 99.13% - Learning rate: 0.0015625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rnn_model = Train_Model(rnn_model, model_type='RNN', learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_model = Train_Model(cnn_model, model_type='CNN', learning_rate = 0.1)\n",
    "#torch.save(cnn_model,f'{version}_cnn.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-07-27T06:48:24.392518Z",
     "iopub.status.busy": "2022-07-27T06:48:24.392164Z",
     "iopub.status.idle": "2022-07-27T06:48:25.789155Z",
     "shell.execute_reply": "2022-07-27T06:48:25.788024Z",
     "shell.execute_reply.started": "2022-07-27T06:48:24.392488Z"
    }
   },
   "outputs": [],
   "source": [
    "output = open(f'./result.csv', 'w')\n",
    "output.write('id,action')\n",
    "\n",
    "rnn_model.eval()\n",
    "cnn_model.eval()\n",
    "\n",
    "i=0\n",
    "test_data = []\n",
    "for dt in range(len(test_normalized_data_list)):\n",
    "    data = []\n",
    "    for i in range(0, len(test_normalized_data_list[dt]) - time_length + 1, sliding_step):\n",
    "        data.append(test_normalized_data_list[dt][i:i+time_length])\n",
    "    \n",
    "    data = torch.from_numpy(np.stack(data))\n",
    "    prediction_rnn = rnn_model(data.to(device))\n",
    "    pre_rnn = prediction_rnn.argmax(dim=1)\n",
    "    # Shape: [samples, channel=1, height, width]\n",
    "    #prediction_cnn = cnn_model(data.unsqueeze(1).to(device))\n",
    "    #pre_cnn = prediction_cnn.argmax(dim=1)\n",
    "\n",
    "    '''\n",
    "    if pre_rnn.bincount()[pre_rnn.bincount().argmax().item()].item()/pre_rnn.shape[0] > pre_cnn.bincount()[pre_cnn.bincount().argmax().item()].item()/pre_cnn.shape[0]:\n",
    "        print(dt, pre_rnn.bincount()[pre_rnn.bincount().argmax().item()].item()/pre_rnn.shape[0])\n",
    "        output.write(f\"\\n{dt},{pre_rnn.bincount().argmax().item()}\")\n",
    "    else:\n",
    "        print(dt, pre_cnn.bincount()[pre_cnn.bincount().argmax().item()].item()/pre_cnn.shape[0])\n",
    "        output.write(f\"\\n{dt},{pre_cnn.bincount().argmax().item()}\")\n",
    "    print(dt, pre_rnn.bincount()[pre_rnn.bincount().argmax().item()].item()/pre_rnn.shape[0])\n",
    "    '''\n",
    "    output.write(f\"\\n{dt},{pre_rnn.bincount().argmax().item()}\")\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f155fbeb9494e5ce992090b8427abe3542dae7719d8ea0d05cb0b78608edd18"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
